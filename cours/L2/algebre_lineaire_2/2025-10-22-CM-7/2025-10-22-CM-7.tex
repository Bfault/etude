\documentclass[a4paper, 12pt]{article}

\usepackage{utils}

\renewcommand*{\today}{22 October 2025}

\begin{document}

\hotbox{Algèbre linéaire 2}{CM 7}{\today}

\begin{proposition}{}{}
    Pour tout n-uplet $(x_1, \cdots, x_n)$ et tout $\varphi \in \wedge^{*n}(E)$, on a
    $$
    \forall u \in \mathcal{L}(E), \quad \varphi(u(x_1), \cdots, u(x_n)) = \det(u) \varphi(x_1, \cdots, x_n).
    $$
\end{proposition}

\begin{demonstration}
    On a nécessairement $\varphi = \lambda \Delta, k \in \K$ d'après le chapitre précédent.

    On a alors $\varphi(u(x_1), \cdots, u(x_n)) = \lambda \Delta(u(x_1), \cdots, u(x_n))$.

    Il suffit de démontrer la propriété pour $\varphi = \Delta$.

    Dans la base canonique, on a
    $$
    \forall j \in \llbracket 1, n \rrbracket, \quad x_j = \sum\limits_{i = 1}^n x_{i,j} e^i
    $$

    $X$ est la matrice des coordonnées de la famille $(x_1, \cdots, x_n)$ dans la base canonique.
    De même, $U = Mat_{Can}(u)$.
    On a alors
    $$
    y_j = U \begin{pmatrix}
        x_{1,j} \\
        \vdots  \\
        x_{n,j}
    \end{pmatrix}
    $$
    La matrice des coordonnées de la famille $(u(x_1), \cdots, u(x_n))$ dans la base canonique est donc $Y = UX$.
    On a donc
    $$
        \det(Y) = \det(U) \det(X)
    $$
\end{demonstration}

\begin{theoreme}{}{}
    \begin{enumerate}
        \item Le déterminant de l'application identité vaut 1.
        \item Si $u, v \in \L(E)$, alors $\det(u \circ v) = \det(u) \det(v)$.
        \item Un endomorphisme $u \in \L(E)$ est un isomorphisme si et seulement si $\det(u) \neq 0$. Dans ce cas, on a
        $$
        \det(u^{-1}) = \frac{1}{\det(u)}
        $$
    \end{enumerate}
\end{theoreme}

\begin{demonstration}
    Il suffit de démontrer les propriétés dans une base quelconque et d'utiliser les matrices associées.
\end{demonstration}

\begin{definition}
    Soit $A = (a_{i,j}) \in M_n(\K)$.
    \begin{enumerate}
        \item Le terme $(-1)^{i+j} \Delta_{i,j}$ est appelé \textbf{cofacteur} de $a_{i,j}$ on le note $A_{i,j}$.
        \item On appelle \textbf{comatrice} de $A$ la matrice des cofacteurs. On la note $com(A)$.
    \end{enumerate}
\end{definition}

\begin{theoreme}{}{}
    Soit $A \in M_n(\K)$. On a
    $$
    A \times com(A)^T = \det(A) Id_n = com(A)^T \times A
    $$
\end{theoreme}

\begin{hotwarn}
    À finir
\end{hotwarn}

\section{Réduction des endomorphismes}

\begin{definition}
    Soit $u \in \L(E)$ et $\lambda \in \K$. On pose
    $$
    E_\lambda = \{x \in E \mid u(x) = \lambda x\}
    $$

    $\lambda$ est dit \textbf{valeur propre} de $u$ si $E_\lambda \neq \{0_E\}$.\n
    $E_\lambda$ est appelé \textbf{espace propre} associé à $\lambda$.\n
    Les éléments de $E_\lambda \backslash \{0_E\}$ sont appelés \textbf{vecteurs propres} associés à $\lambda$.
\end{definition}

\begin{proposition}{}{}
    Soit $u \in \L(E)$ et $\lambda \in \K$. On a
    $$
    E_\lambda = \ker(u - \lambda Id_E)
    $$
\end{proposition}

\begin{demonstration}
    D'après la définition de $E_\lambda$, on a
    \begin{align*}
        E_\lambda & = \{x \in E \mid u(x) = \lambda x\} \\
                  & = \{x \in E \mid u(x) - \lambda x = 0_E\} \\
                  & = \{x \in E \mid (u - \lambda Id_E)(x) = 0_E\} \\
                  & = \ker(u - \lambda Id_E)
    \end{align*}
\end{demonstration}

\begin{proposition}{}{}
    $E_\lambda$ est un sous-espace vectoriel de $E$.
\end{proposition}

\begin{demonstration}
    Soit $x, y \in E_\lambda$ et $\alpha, \beta \in \K$

    On a $u(x) = \lambda x$ et $u(y) = \lambda y$

    Donc
    \begin{align*}
        u(\alpha x + \beta y) & = \alpha u(x) + \beta u(y) \\
                              & = \alpha \lambda x + \beta \lambda y \\
                              & = \lambda (\alpha x + \beta y)
    \end{align*}

    Donc $\alpha x + \beta y \in E_\lambda$

    Ainsi, $E_\lambda$ est un sous-espace vectoriel de $E$.
\end{demonstration}

\begin{remarque}
    $0 \in E_\lambda$ donc $E_\lambda$ est non vide.
\end{remarque}

\end{document}